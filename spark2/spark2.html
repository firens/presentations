<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>Spark 2</title>

    <meta name="description" content="Spark 2, loads of new features">
    <meta name="author" content="Samuel Durand">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="../revealjs/css/reveal.css">
    <link rel="stylesheet" href="../revealjs/css/theme/black.css" id="theme">
    <link rel="stylesheet" href="css/spark2.css"/>

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="../revealjs/lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? '../revealjs/css/print/pdf.css' : '../revealjs/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>

    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body>

<div class="reveal">

    <div class="slides">
        <section>
            <h1 style="text-transform: none">Spark 2.0</h1>
            <h3>Easier, Faster and Smarter ?</h3>
            <img class="logo" src="img/spark-logo.png"/>
            <p>
                <small>Presentation by <a href="https://twitter.com/samudurand">Samuel Durand</a></small>
            </p>
        </section>

        <section>
            <h3>Today we will talk about...</h3>
            <ul>
                <li>What is Spark ?</li>
                <li>Spark 2 : Goals</li>
                <li>New features and improvements</li>
                <li>Future</li>
                <li>Demo</li>
            </ul>
        </section>

        <section>

            <section>
                <h2 style="margin-bottom: 1em">Apache Spark</h2>
                <p>Created in <b class="highlight-blue">2009</b> by  Matei Zaharia</p>
                <p>Maintained since <b class="highlight-blue">2013</b> by the Apache Foundation</p>
                <br/>
                <p>Version <b class="highlight-orange">2.0</b> released in June <b class="highlight-blue">2016</b></li></p>
                <br/>
                <p>One of the most active Apache project</p>
            </section>

            <section>
                <h2 style="margin-bottom: 1em">What is Spark ?</h2>
                <p>Advertised as <i>"A fast and general engine for large-scale data processing"</i></p>
                <p>A <span class="highlight-orange">data processing</span> platform,
                    running on a <span class="highlight-orange">cluster</span></p>
                <p>Designed to handle very large amount of archived or live data very <span class="highlight-orange">quickly</span> and <span class="highlight-orange">efficiently</span>.</p>
            </section>

            <section>
                <h2>What is Spark ?</h2>
                <ul>
                    <li>Designed for <span class="highlight-orange">analytical</span>/transforming operations</li>
                    <li>Minimal amount code</li>
                    <li>Various languages : Scala, Java, Python... </li>
                    <li>Handle data <span class="highlight-orange">in memory</span></li>
                    <li>Very large cluster (> 8000 nodes)</li>
                </ul>
            </section>

            <section>
                <h2 style="margin-bottom: 1em">Features</h2>
                <ul>
                    <li>Data analysis</li>
                    <li>Work with RDDs or SQL like queries</li>
                    <li>Streaming</li>
                    <li>Machine Learning</li>
                    <li>APIs for many datasources <br/>(HDFS, Cassandra, Kafka...)</li>
                </ul>
            </section>

            <section>
                <h2>Spark Ecosystem</h2>
                <img class="logo" src="img/spark-ecosystem.png"/>
            </section>

            <section>
                <p>Code example ?</p>
                <pre><code data-trim  class="scala">
val rdd = sparkContext.textFile("hdfs://...")

rdd.flatMap(line => line.split(" "))
.map(word => (word, 1)).reduceByKey(_ + _)
.saveAsTextFile("hdfs://...")
                </code></pre>
            </section>

            <section>
                What you would do with Spark ? What you would not do ?
            </section>

            <section>
                <h2 style="margin-bottom: 1em">A note on Databricks</h2>
                <p>Founded by Matei Zaharia and other co-founders of Spark</p>
                <img class="logo" src="img/databricks-logo.png"/>
                <p>Provides services and support for Spark</p>
                <p>Also offers an <span class="highlight-orange">online platform</span> for experimenting/training (free option since June 2016)</p>
            </section>

        </section>

        <section>
            <h2>Spark 2 : What's new ?</h2>
            <ul>
                <li class="fragment">Focus on <i>Datasets</i> instead of <i>RDDs</i></li>
                <li class="fragment">Unify <i>Datasets</i> and <i>Dataframes</i></li>
                <li class="fragment"><b class="highlight-orange">SparkSession</b> : single entry point to data APIs</li>
                <li class="fragment"><b class="highlight-orange">SparkSQL</b> : all 99 TPC-DS queries</li>
                <li class="fragment">Performance improvements : <b class="highlight-orange">Tungsten</b></li>
                <li class="fragment">Spark.ML replaces MLlib</li>
                <li class="fragment">Window functions</li>
                <li class="fragment">Many more : CSV support, more features for R users...</li>
            </ul>
        </section>

        <section>

            <section>

                <h2>RDDs VS Datasets</h2>

                <p>Why choose to work with Datasets ?</p>

            </section>

            <section>

                <h2 style="margin-bottom: 1em">Resilient Distributed Dataset (RDD)</h2>

                <ul>
                    <li class="fragment">Immutable distributed collection of Objects</li>
                    <div class="fragment">
                        <li>Unstructured data</li>
                        <pre><code data-trim  class="scala">
val lines = sc.textFile("data.txt")
val total = lines.map(s => s.length)
                 .reduce((a, b) => a + b)
                        </code></pre>
                    </div>
                    <li class="fragment">Functional programming</li>
                    <li class="fragment">Syntax errors caught at compile time</li>
                    <li class="fragment">Limited optimizations</li>
                    <li class="fragment">More control over operations</li>
                </ul>

            </section>

            <section>

                <h2 style="margin-bottom: 1em">Datasets</h2>

                <ul>
                    <li class="fragment">Immutable distributed collection of Objects</li>
                    <li class="fragment"><b class="highlight-orange">Structured data</b>, similar to tables (json, sql...)</li>
                    <li class="fragment">Rich semantics, high-level abstractions</li>
                    <li class="fragment">3 APIs available : SQL, Dataframe, Dataset</li>
                    <li class="fragment"><b class="highlight-orange">Type safe : operate on domain objects with lambda functions</b></li>
                    <li class="fragment">Syntax and analysis errors caught at <b class="highlight-orange">compile time</b></li>
                    <li class="fragment">Structure <b class="highlight-orange">limits</b> what can be done :
                        <br/><b class="highlight-orange">Storage and performance optimizations</b></li>
                </ul>

            </section>

            <section>

                <h2>Catalyst : Query planner</h2>

                <p>Decides the best way to perform a query by trying several possibilities</p>

                <img src="img/catalyst.png"/>

            </section>

            <section>

                <h2>Optimizations</h2>

                <p>Better <b class="highlight-orange">performances</b> with relational execution engine</p>
                <img src="img/memory-usage.png"/>

                <p>Spark knows structure of data : it can optimize <b class="highlight-orange">storage</b></p>
                <img src="img/performance.png"/>

            </section>

            <section>

                <h2>Optimizations</h2>

                <p>Serialized using <b class="highlight-orange">Encoders</b> into Tungsten binary format</p>

                <p>Far better performances with less space (up to 2x less)</p>

                <img src="img/encoder-performances.png"/>

                <p>Operate Directly On Serialized Data when possible</p>

            </section>

            <section>

                <h2>Structured APIs</h2>

                <p>SQL</p>
                    <pre><code data-trim  class="scala">
val peopleDF = spark.read.json("people.json")
peopleDF.createOrReplaceTempView("people")
spark.sql("SELECT name FROM people").show()
                    </code></pre>
                <p>Dataframes = Dataset[Row]</p>
                    <pre><code data-trim  class="scala">
val peopleDF = spark.read.json("people.json")
peopleDF.select($"name", $"age" + 1).show()
                    </code></pre>
                <p>Datasets</p>
                <pre><code data-trim  class="scala">
val personDS = spark.read.json("people.json").as[Person]
peopleDs.foreach(p => println(s"| ${p.name} | ${p.age + 1} |"))
                    </code></pre>
            </section>
            
            <section>
                
                <h2>Structured APIs</h2>
                
                <img src="img/structured-apis.png">

                <div class="fragment">
                    <p >Analysis errors caught before job starts</p>

                    <pre><code data-trim  class="scala">
case class University(numStudents: Int)
val schools = sqlContext.read.json("/schools.json").as[University]
org.....AnalysisException:
  Cannot upcast `numStudents` from string to int as it may truncate
                    </code></pre>
                </div>
                
            </section>

        </section>

        <section>

            <section>

                <h2>SparkSession</h2>

                <p>A unique entry point to all APIs</p>

            </section>

            <section>

                <h2 style="margin-bottom: 1em">Before</h2>

                <p>SparkContext : RDD Api</p>
                <pre><code data-trim  class="scala">
val conf = new SparkConf().setAppName("Spark App")
                      .setMaster("local[2]")
val sc = new SparkContext(conf)
                </code></pre>

                <p>SqlContext : Dataframe Api</p>
                <pre><code data-trim  class="scala">
val sqlContext = new org.apache.spark.sql.SQLContext(sc)
                </code></pre>

                <p><div style="display: inline-block">HiveContext : Dataframe Api, Window functions <br/>
                        and Hive compatibility</div> <img class="logo" src="img/hive-logo.png"/> </p>
                <pre><code data-trim  class="scala">
val hContext = new org.apache.spark.sql.hive.HiveContext(sc)
                </code></pre>


            </section>

            <section>

                <h2>Problems</h2>

                <p style="margin-bottom: 1em"><b class="highlight-orange">Confusion</b> between SqlContext and HiveContext : which one to choose ?</p>

                <p style="margin-bottom: 1em">Heavy dependence on Hive especially for <b class="highlight-orange">window functions</b></p>

                <p>Hive has lots of <b class="highlight-orange">dependencies</b></p>

            </section>

            <section>

                <h2>In Spark 2</h2>
                <pre><code data-trim  class="scala">

val spark = SparkSession.builder.master("local[2]")
                                .appName("Spark app")
                                .getOrCreate()

val personsDF = spark.read.json("persons.json")

val personsDS = personsDF.as[Person]
                </code></pre>

                <div class="fragment">
                    <p style="margin-top: 1em; margin-bottom: 1em">The SparkContext is also available</p>

                    <pre><code data-trim  class="scala">
val sc = spark.sparkContext
                    </code></pre>

                 </div>

                <p class="fragment">But... still dependent on Hive</p>
            </section>

        </section>

        <section>

            <section>

                <h2>Tungsten 2nd generation</h2>

            </section>

            <section>

                <h2>What is Tungsten ?</h2>

                <p>Project aiming to improve the efficiency of memory and CPU for Spark applications.</p>

                <ul class="fragment">
                    <li style="margin-bottom: 2%;">Memory : eliminate the <b class="highlight-orange">overhead</b> of JVM object model</li>
                    <li style="margin-bottom: 2%;">Find ways around the limitations of <b class="highlight-orange">garbage collection</b></li>
                    <li style="margin-bottom: 2%;"><b class="highlight-orange">Cache-aware</b> computation: exploit memory hierarchy</li>
                    <li style="margin-bottom: 2%;">Improve <b class="highlight-orange">bytecode generation</b> to exploit modern compilers and CPUs</li>
                </ul>

            </section>

            <section>

                <h2>Tungsten 2nd Generation</h2>

                <p>Introduce a new mechanism : <i>whole-stage code generation</i></p>

                <p class="fragment">Emits <b class="highlight-orange">optimized bytecode</b> at runtime that collapses
                    the entire query into a <b class="highlight-orange">single function</b></p>

                <ul>
                    <li class="fragment">Eliminates virtual function calls</li>
                    <li class="fragment">Uses CPU registers for intermediate data</li>
                </ul>

            </section>

            <section>

                <h2 style="margin-bottom: 1em">Volcano Iterator Model</h2>

                <img class="fragment logo" data-fragment-index="1" style="margin-left:1em; float: right;" src="img/volcano-iterator-model.png"/>

                <p style="margin-bottom: 2em">A query consists of multiple operators, and each operator presents an interface, next()</p>

                <p class="fragment" style="margin-bottom: 2em" data-fragment-index="1"><i>select count(*) from store_sales<br/> where ss_item_sk = 1000</i></p>

                <ul class="fragment" data-fragment-index="2" style="width: 65%">
                    <li>Process any combination of operations</li>
                    <li>No concerns on the type of data</li>
                </ul>

            </section>

            <section>

                <h2 style="margin-bottom: 1em">Compared with hand-written code ?</h2>

                <pre style="box-shadow: none"><code data-trim  class="java">
var count = 0
for (ss_item_sk in store_sales) {
  if (ss_item_sk == 1000) {
    count += 1
  }
}
                </code></pre>

                <img style="margin-top: 1em" class="fragment" src="img/volcano-vs-hand-written-code.png"/>

            </section>

            <section>

                <h2>Why such a difference ?</h2>

                <ul>
                    <li>No virtual function calls</li>
                    <li>No need to save data in memory</li>
                    <li>CPUs are incredibly efficient when handling for loops</li>
                </ul>

            </section>

            <section>

                <h2>Whole-stage code generation</h2>

                <img style="background: white; padding: 15px" class="logo" src="img/whole-stage-code-generation-model.png"/>

            </section>

        </section>

        <section>

            RDD : Object oriented design, cannot optimise as much as Dataframe

            Dataframe and SparkSQL : high level api to work with structured Data (database tables, JSON...)
                Let Spark automatically optimize storage and computation with Tungstene and Catalyst optimizer
                like working on data on raw binary form

            Dataset : extension of Dataframe with same advantages, but type-safe and object-oriented
            A Dataset is a strongly-typed, immutable collection of objects that are mapped to a relational schema.

            query planner

            Datasets also leverage Tungsten’s fast in-memory encoding

            compile-time type safety – meaning production applications can be checked for errors before they are run

            direct operations over user-defined classes

            At the core of the Dataset API is a new concept called an encoder, which is responsible for converting between JVM objects and tabular representation. The tabular representation is stored using Spark’s internal Tungsten binary format, allowing for operations on serialized data and improved memory utilization.

        </section>

    </div>

</div>

<script src="../revealjs/lib/js/head.min.js"></script>
<script src="../revealjs/js/reveal.js"></script>

<script>

    // Full list of configuration options available at:
    // https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,

        transition: 'convex', // none/fade/slide/convex/concave/zoom

        dependencies: [
            {
                src: '../revealjs/lib/js/classList.js', condition: function () {
                return !document.body.classList;
            }
            },
            {
                src: '../revealjs/plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: '../revealjs/plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: '../revealjs/plugin/highlight/highlight.js', async: true, condition: function () {
                return !!document.querySelector('pre code');
            }, callback: function () {
                hljs.initHighlightingOnLoad();
            }
            },
            {src: '../revealjs/plugin/zoom-js/zoom.js', async: true},
            {src: '../revealjs/plugin/notes/notes.js', async: true}
        ]
    });

</script>

</body>
</html>
